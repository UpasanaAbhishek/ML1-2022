{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed9fc7a4",
   "metadata": {},
   "source": [
    "## Aparna K\n",
    "## 21BDA24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba67edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part1: Building the CNN\n",
    "\n",
    "#import keras library and packages\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0576864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9eb3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4933a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step2: Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2))) #pool size 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a41cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep-2\n",
    "classifier.add(Conv2D(16, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2))) #pool size 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a1f0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After step1 and step2 we get the first convolution layer\n",
    "\n",
    "#Step3: Flattening\n",
    "classifier.add(Flatten())\n",
    "#By flattening we get a column vector wich is used as input for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ab8a511",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Step4: Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu')) #Dense of hidden layer (128)\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid')) #Output has just 1 neuron,\n",
    "#beecause it is a binary classification (0 or 1)\n",
    "#ReLu is used in the hidden layer of ANN and sigmoid is used in the output layer of neuron\n",
    "#Connection of flattening output to ANN inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b39610a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6b0e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part2: Fitting the CNN to the images from dataset\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29725093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train data \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3f4a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare test data\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c219256b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3491 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Training dataset directory\n",
    "training_set = train_datagen.flow_from_directory(r\"C:\\Users\\acm\\Desktop\\gender\\train\",\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2d77599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#testing dataset directory\n",
    "test_set = test_datagen.flow_from_directory(r\"C:\\Users\\acm\\Desktop\\gender\\test\",\n",
    "                                               target_size = (64,64),\n",
    "                                               batch_size = 16,\n",
    "                                               class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53bd6b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-3c2081e1a3dd>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000258C7D98820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000258C7D98820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.6975WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000258CB0A6550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000258CB0A6550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "219/219 [==============================] - 35s 151ms/step - loss: 0.5610 - accuracy: 0.6975 - val_loss: 0.3537 - val_accuracy: 0.8550\n",
      "Epoch 2/25\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 0.3816 - accuracy: 0.8373 - val_loss: 0.2395 - val_accuracy: 0.9100\n",
      "Epoch 3/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.3060 - accuracy: 0.8679 - val_loss: 0.3853 - val_accuracy: 0.8100\n",
      "Epoch 4/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.3024 - accuracy: 0.8771 - val_loss: 0.2103 - val_accuracy: 0.9250\n",
      "Epoch 5/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2763 - accuracy: 0.8889 - val_loss: 0.3111 - val_accuracy: 0.8600\n",
      "Epoch 6/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2721 - accuracy: 0.8840 - val_loss: 0.1954 - val_accuracy: 0.9150\n",
      "Epoch 7/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2606 - accuracy: 0.8937 - val_loss: 0.1907 - val_accuracy: 0.9350\n",
      "Epoch 8/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2320 - accuracy: 0.9092 - val_loss: 0.1914 - val_accuracy: 0.9200\n",
      "Epoch 9/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2218 - accuracy: 0.9123 - val_loss: 0.1802 - val_accuracy: 0.9400\n",
      "Epoch 10/25\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 0.2161 - accuracy: 0.9135 - val_loss: 0.1466 - val_accuracy: 0.9200\n",
      "Epoch 11/25\n",
      "219/219 [==============================] - 12s 52ms/step - loss: 0.2110 - accuracy: 0.9149 - val_loss: 0.1763 - val_accuracy: 0.9400\n",
      "Epoch 12/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.2018 - accuracy: 0.9172 - val_loss: 0.1541 - val_accuracy: 0.9450\n",
      "Epoch 13/25\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.1819 - accuracy: 0.9304 - val_loss: 0.1341 - val_accuracy: 0.9400\n",
      "Epoch 14/25\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.1975 - accuracy: 0.9227 - val_loss: 0.1411 - val_accuracy: 0.9450\n",
      "Epoch 15/25\n",
      "219/219 [==============================] - 12s 54ms/step - loss: 0.1895 - accuracy: 0.9304 - val_loss: 0.2184 - val_accuracy: 0.9100\n",
      "Epoch 16/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1919 - accuracy: 0.9195 - val_loss: 0.1913 - val_accuracy: 0.9300\n",
      "Epoch 17/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1856 - accuracy: 0.9301 - val_loss: 0.1794 - val_accuracy: 0.9250\n",
      "Epoch 18/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1661 - accuracy: 0.9347 - val_loss: 0.1430 - val_accuracy: 0.9400\n",
      "Epoch 19/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1622 - accuracy: 0.9373 - val_loss: 0.1343 - val_accuracy: 0.9500\n",
      "Epoch 20/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1550 - accuracy: 0.9404 - val_loss: 0.1302 - val_accuracy: 0.9300\n",
      "Epoch 21/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1447 - accuracy: 0.9450 - val_loss: 0.1270 - val_accuracy: 0.9450\n",
      "Epoch 22/25\n",
      "219/219 [==============================] - 11s 52ms/step - loss: 0.1447 - accuracy: 0.9441 - val_loss: 0.1329 - val_accuracy: 0.9450\n",
      "Epoch 23/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.1518 - accuracy: 0.9430 - val_loss: 0.1288 - val_accuracy: 0.9500\n",
      "Epoch 24/25\n",
      "219/219 [==============================] - 11s 50ms/step - loss: 0.1476 - accuracy: 0.9396 - val_loss: 0.1135 - val_accuracy: 0.9400\n",
      "Epoch 25/25\n",
      "219/219 [==============================] - 11s 51ms/step - loss: 0.1439 - accuracy: 0.9444 - val_loss: 0.1760 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x258c7f20d00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit that dataset to the classifier\n",
    "classifier.fit_generator(training_set,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a28743b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'female': 0, 'male': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b4c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39a29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d5ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc24cfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba7258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442f7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f3005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
