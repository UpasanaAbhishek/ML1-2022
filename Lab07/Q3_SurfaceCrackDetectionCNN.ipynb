{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model on Surface Cracks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21BDA26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-12T00:24:34.590933Z",
     "iopub.status.busy": "2022-05-12T00:24:34.590262Z",
     "iopub.status.idle": "2022-05-12T00:24:40.535038Z",
     "shell.execute_reply": "2022-05-12T00:24:40.534152Z",
     "shell.execute_reply.started": "2022-05-12T00:24:34.590824Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dbed157ce865>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mMaxPool2D\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:24:40.537259Z",
     "iopub.status.busy": "2022-05-12T00:24:40.536975Z",
     "iopub.status.idle": "2022-05-12T00:24:40.541738Z",
     "shell.execute_reply": "2022-05-12T00:24:40.540670Z",
     "shell.execute_reply.started": "2022-05-12T00:24:40.537220Z"
    }
   },
   "outputs": [],
   "source": [
    "# labels = ['Negative', 'Positive']\n",
    "# img_size = 128\n",
    "# def read_images(data_dir):\n",
    "#     data = [] \n",
    "#     \n",
    "#     for label in labels: \n",
    "#         path = os.path.join(data_dir, label)\n",
    "#         class_num = labels.index(label)\n",
    "#         count = 5000\n",
    "#         for img in os.listdir(path):\n",
    "#             img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "#             resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
    "#             data.append([resized_arr, class_num])\n",
    "#             count-=1;\n",
    "#             if count==0:\n",
    "#                 break\n",
    "#     return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:24:40.544251Z",
     "iopub.status.busy": "2022-05-12T00:24:40.543656Z",
     "iopub.status.idle": "2022-05-12T00:24:40.553310Z",
     "shell.execute_reply": "2022-05-12T00:24:40.552465Z",
     "shell.execute_reply.started": "2022-05-12T00:24:40.544210Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['Negative', 'Positive']\n",
    "img_size = 128\n",
    "def read_images(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
    "            data.append([resized_arr, class_num])\n",
    "            \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:24:40.556583Z",
     "iopub.status.busy": "2022-05-12T00:24:40.556132Z",
     "iopub.status.idle": "2022-05-12T00:27:10.346817Z",
     "shell.execute_reply": "2022-05-12T00:27:10.345964Z",
     "shell.execute_reply.started": "2022-05-12T00:24:40.556541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "Dataset = read_images('../input/surface-crack-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:10.348869Z",
     "iopub.status.busy": "2022-05-12T00:27:10.348342Z",
     "iopub.status.idle": "2022-05-12T00:27:12.305011Z",
     "shell.execute_reply": "2022-05-12T00:27:12.304222Z",
     "shell.execute_reply.started": "2022-05-12T00:27:10.348827Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for feature, label in Dataset:\n",
    "    x.append(feature)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, img_size, img_size, 1)\n",
    "x = x / 255\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:12.306633Z",
     "iopub.status.busy": "2022-05-12T00:27:12.306346Z",
     "iopub.status.idle": "2022-05-12T00:27:14.313261Z",
     "shell.execute_reply": "2022-05-12T00:27:14.312342Z",
     "shell.execute_reply.started": "2022-05-12T00:27:12.306596Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:14.315281Z",
     "iopub.status.busy": "2022-05-12T00:27:14.315008Z",
     "iopub.status.idle": "2022-05-12T00:27:14.501685Z",
     "shell.execute_reply": "2022-05-12T00:27:14.500774Z",
     "shell.execute_reply.started": "2022-05-12T00:27:14.315246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del x,y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:14.503710Z",
     "iopub.status.busy": "2022-05-12T00:27:14.503226Z",
     "iopub.status.idle": "2022-05-12T00:27:17.468241Z",
     "shell.execute_reply": "2022-05-12T00:27:17.467476Z",
     "shell.execute_reply.started": "2022-05-12T00:27:14.503661Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 00:27:14.618387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 2)       20        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 4)         76        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 70,714\n",
      "Trainable params: 70,458\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 00:27:14.722302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:14.723085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:14.724212: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-12 00:27:14.724561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:14.725304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:14.725995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:16.992637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:16.993543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:16.994274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-12 00:27:16.995628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(2,3,padding=\"same\", activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(4,3,padding=\"same\", activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(8,3,padding=\"same\", activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(16,3,padding=\"same\", activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape = X_train.shape[1:]))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# model.add(Conv2D(256, 3, padding=\"same\", activation=\"relu\"))\n",
    "# model.add(MaxPool2D())\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:17.469987Z",
     "iopub.status.busy": "2022-05-12T00:27:17.469437Z",
     "iopub.status.idle": "2022-05-12T00:27:17.477744Z",
     "shell.execute_reply": "2022-05-12T00:27:17.476708Z",
     "shell.execute_reply.started": "2022-05-12T00:27:17.469944Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(\n",
    "            self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        return\n",
    "\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:17.481211Z",
     "iopub.status.busy": "2022-05-12T00:27:17.480637Z",
     "iopub.status.idle": "2022-05-12T00:27:17.490961Z",
     "shell.execute_reply": "2022-05-12T00:27:17.490099Z",
     "shell.execute_reply.started": "2022-05-12T00:27:17.481172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:27:17.494033Z",
     "iopub.status.busy": "2022-05-12T00:27:17.493350Z",
     "iopub.status.idle": "2022-05-12T00:47:44.435862Z",
     "shell.execute_reply": "2022-05-12T00:47:44.434739Z",
     "shell.execute_reply.started": "2022-05-12T00:27:17.493994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 00:27:18.262054: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1966080000 exceeds 10% of free system memory.\n",
      "2022-05-12 00:27:20.340880: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1966080000 exceeds 10% of free system memory.\n",
      "2022-05-12 00:27:21.778016: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 00:27:23.375522: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - ETA: 0s - loss: 0.1251 - accuracy: 0.9597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 00:27:32.639350: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 655360000 exceeds 10% of free system memory.\n",
      "2022-05-12 00:27:33.298562: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 655360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 13s 42ms/step - loss: 0.1251 - accuracy: 0.9597 - val_loss: 0.5352 - val_accuracy: 0.5059\n",
      "Epoch 2/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0369 - accuracy: 0.9882 - val_loss: 0.1322 - val_accuracy: 0.9863\n",
      "Epoch 3/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.0706 - val_accuracy: 0.9909\n",
      "Epoch 4/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.0377 - val_accuracy: 0.9923\n",
      "Epoch 5/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0233 - accuracy: 0.9922 - val_loss: 0.0283 - val_accuracy: 0.9899\n",
      "Epoch 6/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0184 - val_accuracy: 0.9945\n",
      "Epoch 7/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0691 - val_accuracy: 0.9748\n",
      "Epoch 8/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0186 - val_accuracy: 0.9934\n",
      "Epoch 9/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.0220 - val_accuracy: 0.9926\n",
      "Epoch 10/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0172 - val_accuracy: 0.9944\n",
      "Epoch 11/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0155 - val_accuracy: 0.9953\n",
      "Epoch 12/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0369 - val_accuracy: 0.9873\n",
      "Epoch 13/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
      "Epoch 14/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0111 - val_accuracy: 0.9966\n",
      "Epoch 15/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0158 - val_accuracy: 0.9952\n",
      "Epoch 16/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0097 - val_accuracy: 0.9970\n",
      "Epoch 17/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0088 - val_accuracy: 0.9977\n",
      "Epoch 18/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
      "Epoch 19/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0092 - val_accuracy: 0.9974\n",
      "Epoch 20/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0117 - val_accuracy: 0.9968\n",
      "Epoch 21/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0169 - val_accuracy: 0.9952\n",
      "Epoch 22/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0102 - val_accuracy: 0.9968\n",
      "Epoch 23/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
      "Epoch 24/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0108 - val_accuracy: 0.9971\n",
      "Epoch 25/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0140 - val_accuracy: 0.9969\n",
      "Epoch 26/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0194 - val_accuracy: 0.9947\n",
      "Epoch 27/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0098 - val_accuracy: 0.9963\n",
      "Epoch 28/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "Epoch 29/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0192 - val_accuracy: 0.9953\n",
      "Epoch 30/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0336 - val_accuracy: 0.9913\n",
      "Epoch 31/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0094 - val_accuracy: 0.9979\n",
      "Epoch 32/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9979\n",
      "Epoch 33/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0091 - val_accuracy: 0.9979\n",
      "Epoch 34/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9979\n",
      "Epoch 35/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0104 - val_accuracy: 0.9971\n",
      "Epoch 36/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 0.9975\n",
      "Epoch 37/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.7616e-04 - accuracy: 0.9999 - val_loss: 0.0100 - val_accuracy: 0.9974\n",
      "Epoch 38/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 8.5669e-04 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9979\n",
      "Epoch 39/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.7825e-04 - accuracy: 0.9999 - val_loss: 0.0092 - val_accuracy: 0.9976\n",
      "Epoch 40/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 7.8741e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9974\n",
      "Epoch 41/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.7345e-04 - accuracy: 0.9999 - val_loss: 0.0132 - val_accuracy: 0.9968\n",
      "Epoch 42/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 5.1162e-04 - accuracy: 0.9999 - val_loss: 0.0106 - val_accuracy: 0.9973\n",
      "Epoch 43/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.2676e-04 - accuracy: 0.9999 - val_loss: 0.0106 - val_accuracy: 0.9974\n",
      "Epoch 44/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.2134e-04 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9971\n",
      "Epoch 45/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.0465e-04 - accuracy: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9973\n",
      "Epoch 46/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 5.8464e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9976\n",
      "Epoch 47/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.4369e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9978\n",
      "Epoch 48/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.4113e-04 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9973\n",
      "Epoch 49/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.0978e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "Epoch 50/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.3621e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9978\n",
      "Epoch 51/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.8819e-04 - accuracy: 0.9999 - val_loss: 0.0169 - val_accuracy: 0.9962\n",
      "Epoch 52/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
      "Epoch 53/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0196 - val_accuracy: 0.9959\n",
      "Epoch 54/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.8707e-04 - accuracy: 0.9998 - val_loss: 0.0209 - val_accuracy: 0.9938\n",
      "Epoch 55/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0133 - val_accuracy: 0.9967\n",
      "Epoch 56/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.2430e-04 - accuracy: 0.9999 - val_loss: 0.0244 - val_accuracy: 0.9941\n",
      "Epoch 57/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.0815e-04 - accuracy: 0.9999 - val_loss: 0.0213 - val_accuracy: 0.9937\n",
      "Epoch 58/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 4.7470e-04 - accuracy: 0.9999 - val_loss: 0.0235 - val_accuracy: 0.9930\n",
      "Epoch 59/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.8808e-04 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9967\n",
      "Epoch 60/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5772e-04 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9976\n",
      "Epoch 61/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.2041e-04 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9972\n",
      "Epoch 62/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.5564e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9972\n",
      "Epoch 63/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9975\n",
      "Epoch 64/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5471e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 65/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.9322e-04 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 66/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.7419e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9976\n",
      "Epoch 67/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 7.6424e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
      "Epoch 68/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.8205e-05 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9978\n",
      "Epoch 69/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 9.2646e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 70/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.9799e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 71/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.3263e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9975\n",
      "Epoch 72/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 7.1566e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 73/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.5475e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9974\n",
      "Epoch 74/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.0452e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9975\n",
      "Epoch 75/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.5601e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9974\n",
      "Epoch 76/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.5470e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9973\n",
      "Epoch 77/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.7544e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9971\n",
      "Epoch 78/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5182e-04 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9970\n",
      "Epoch 79/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.7007e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 80/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 5.8406e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9972\n",
      "Epoch 81/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 6.6763e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 82/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.8099e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9972\n",
      "Epoch 83/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.6001e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9970\n",
      "Epoch 84/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 5.0779e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9974\n",
      "Epoch 85/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.2952e-05 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 86/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.6244e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 87/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1766e-04 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 0.9976\n",
      "Epoch 88/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 5.3605e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9972\n",
      "Epoch 89/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.8076e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9974\n",
      "Epoch 90/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.5979e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
      "Epoch 91/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.2455e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 92/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 3.5442e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9976\n",
      "Epoch 93/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.1640e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9974\n",
      "Epoch 94/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.8343e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9974\n",
      "Epoch 95/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.8821e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "Epoch 96/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.8821e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9975\n",
      "Epoch 97/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.2845e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9973\n",
      "Epoch 98/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.0449e-05 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9973\n",
      "Epoch 99/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 5.3421e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9977\n",
      "Epoch 100/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.0927e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9974\n",
      "Epoch 101/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.7008e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
      "Epoch 102/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.8071e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 103/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 3.0314e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9975\n",
      "Epoch 104/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.4118e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 105/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.1809e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9973\n",
      "Epoch 106/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.8977e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9975\n",
      "Epoch 107/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.8028e-05 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 0.9975\n",
      "Epoch 108/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.6024e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9974\n",
      "Epoch 109/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.4365e-05 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9973\n",
      "Epoch 110/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 2.8731e-05 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9974\n",
      "Epoch 111/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.4493e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9975\n",
      "Epoch 112/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.4176e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 113/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.5668e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
      "Epoch 114/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.0637e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9976\n",
      "Epoch 115/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 5.2661e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 116/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.0751e-05 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 0.9973\n",
      "Epoch 117/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.4149e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9974\n",
      "Epoch 118/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.0330e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9973\n",
      "Epoch 119/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.9302e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9973\n",
      "Epoch 120/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.9670e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 121/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.5170e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9974\n",
      "Epoch 122/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.3031e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
      "Epoch 123/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.7980e-05 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9962\n",
      "Epoch 124/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0168 - val_accuracy: 0.9952\n",
      "Epoch 125/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.8401e-04 - accuracy: 0.9997 - val_loss: 0.0138 - val_accuracy: 0.9970\n",
      "Epoch 126/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 9.6304e-05 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 0.9977\n",
      "Epoch 127/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.1567e-05 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 0.9971\n",
      "Epoch 128/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.9780e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9974\n",
      "Epoch 129/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.2332e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9977\n",
      "Epoch 130/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.5212e-05 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9975\n",
      "Epoch 131/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.3199e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9977\n",
      "Epoch 132/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.9172e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9977\n",
      "Epoch 133/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.2860e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9975\n",
      "Epoch 134/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.1304e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9974\n",
      "Epoch 135/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.6202e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9974\n",
      "Epoch 136/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.3495e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 137/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 2.7828e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9973\n",
      "Epoch 138/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.2805e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9974\n",
      "Epoch 139/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.2660e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9973\n",
      "Epoch 140/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.4322e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9974\n",
      "Epoch 141/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.3620e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9975\n",
      "Epoch 142/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.3347e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
      "Epoch 143/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.8353e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9975\n",
      "Epoch 144/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.1136e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9973\n",
      "Epoch 145/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.2494e-05 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 0.9975\n",
      "Epoch 146/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.5568e-05 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9931\n",
      "Epoch 147/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9970\n",
      "Epoch 148/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.2242e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9955\n",
      "Epoch 149/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.2190e-04 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 150/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.1989e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9972\n",
      "Epoch 151/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.5555e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9971\n",
      "Epoch 152/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.7792e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9972\n",
      "Epoch 153/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.7168e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9972\n",
      "Epoch 154/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.7862e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9972\n",
      "Epoch 155/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.4752e-05 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9963\n",
      "Epoch 156/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.3881e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9973\n",
      "Epoch 157/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.9718e-05 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9976\n",
      "Epoch 158/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.3211e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9974\n",
      "Epoch 159/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.6576e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9972\n",
      "Epoch 160/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 2.4057e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
      "Epoch 161/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.7754e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 162/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.8929e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9973\n",
      "Epoch 163/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5692e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9973\n",
      "Epoch 164/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.7086e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 165/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.9971e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9972\n",
      "Epoch 166/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.3891e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9974\n",
      "Epoch 167/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.5215e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9972\n",
      "Epoch 168/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.7181e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9974\n",
      "Epoch 169/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.8402e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9972\n",
      "Epoch 170/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.7024e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 171/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 2.1377e-05 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9973\n",
      "Epoch 172/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 2.0803e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9972\n",
      "Epoch 173/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.4087e-05 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9971\n",
      "Epoch 174/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.3569e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
      "Epoch 175/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.2345e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 176/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.3423e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9974\n",
      "Epoch 177/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.3497e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 178/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5872e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9974\n",
      "Epoch 179/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.4373e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9975\n",
      "Epoch 180/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.7618e-05 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9969\n",
      "Epoch 181/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.8999e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9976\n",
      "Epoch 182/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.3961e-05 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 183/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.3788e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9974\n",
      "Epoch 184/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.9834e-05 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9972\n",
      "Epoch 185/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.6886e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9973\n",
      "Epoch 186/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.3593e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 187/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.2409e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9977\n",
      "Epoch 188/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1325e-05 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9975\n",
      "Epoch 189/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.5509e-05 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9976\n",
      "Epoch 190/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.0203e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9974\n",
      "Epoch 191/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.0766e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9976\n",
      "Epoch 192/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.8150e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 193/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.0207e-05 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9974\n",
      "Epoch 194/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 1.3748e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 195/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.0276e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
      "Epoch 196/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 8.8918e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9974\n",
      "Epoch 197/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.6515e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 198/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.1330e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9975\n",
      "Epoch 199/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.4896e-06 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 200/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.3424e-06 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9976\n",
      "Epoch 201/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.3313e-06 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9974\n",
      "Epoch 202/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.1376e-05 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 203/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.4981e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 204/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1263e-05 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9973\n",
      "Epoch 205/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.0001e-05 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9974\n",
      "Epoch 206/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1506e-05 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9973\n",
      "Epoch 207/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 8.9963e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 208/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.1026e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 209/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 9.2716e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9973\n",
      "Epoch 210/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 7.7984e-06 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 211/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.4369e-06 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9974\n",
      "Epoch 212/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.7982e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 213/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 7.7988e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9974\n",
      "Epoch 214/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.2643e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 215/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 1.0888e-05 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9974\n",
      "Epoch 216/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.2396e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 217/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 7.5818e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 218/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 8.0009e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9975\n",
      "Epoch 219/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.1629e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 220/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 9.7060e-06 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9973\n",
      "Epoch 221/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 8.5216e-06 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9974\n",
      "Epoch 222/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.8277e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 223/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.9431e-06 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 224/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 1.0353e-05 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9976\n",
      "Epoch 225/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 7.3279e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9975\n",
      "Epoch 226/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 8.1039e-06 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9975\n",
      "Epoch 227/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.8277e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 356/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.6602e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 357/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 7.4532e-06 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9976\n",
      "Epoch 358/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.9325e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 359/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.3496e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 360/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.1555e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9976\n",
      "Epoch 361/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.7277e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 362/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 3.4824e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 363/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 6.7780e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 364/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.0710e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 365/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 3.4013e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 366/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.1393e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 367/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.4611e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 368/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.5060e-06 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9974\n",
      "Epoch 369/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.8118e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 370/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.7830e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 371/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.2540e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 372/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.4277e-06 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 373/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.2469e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 374/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.8845e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 375/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 3.7222e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 376/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.0281e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 377/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 4.5699e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 378/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.2511e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 379/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.2214e-06 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 0.9975\n",
      "Epoch 380/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 5.4571e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9976\n",
      "Epoch 381/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 4.8363e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 382/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 5.5510e-06 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 383/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.3729e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 384/400\n",
      "118/118 [==============================] - 3s 26ms/step - loss: 5.2571e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 385/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.6747e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9975\n",
      "Epoch 386/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.4252e-06 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 387/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 4.1932e-06 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "Epoch 388/400\n",
      "118/118 [==============================] - 3s 27ms/step - loss: 4.8723e-06 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 0.9974\n",
      "Epoch 389/400\n",
      "118/118 [==============================] - 3s 25ms/step - loss: 4.7321e-06 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "Epoch 390/400\n",
      "118/118 [==============================] - 3s 24ms/step - loss: 3.5477e-06 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9975\n",
      "Epoch 391/400\n",
      " 85/118 [====================>.........] - ETA: 0s - loss: 3.9030e-06 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss=\"sparse_categorical_crossentropy\",metrics=['accuracy']) \n",
    "history = model.fit(X_train, y_train, epochs = 400, \n",
    "                    batch_size = 256, \n",
    "                    validation_data = (X_test, y_test), \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:47:44.438183Z",
     "iopub.status.busy": "2022-05-12T00:47:44.437911Z",
     "iopub.status.idle": "2022-05-12T00:47:44.863015Z",
     "shell.execute_reply": "2022-05-12T00:47:44.862267Z",
     "shell.execute_reply.started": "2022-05-12T00:47:44.438153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8b8410bed0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.style.use('ggplot')\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy of Epochs')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend(['train accuracy', 'validation accuracy'], loc='lower right', prop={'size': 12})\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss of Epochs')\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend(['train loss', 'validation loss'], loc='best', prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:56:42.857863Z",
     "iopub.status.busy": "2022-05-12T00:56:42.857385Z",
     "iopub.status.idle": "2022-05-12T00:56:45.345119Z",
     "shell.execute_reply": "2022-05-12T00:56:45.344285Z",
     "shell.execute_reply.started": "2022-05-12T00:56:42.857822Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6ca9eb97c22e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "for i in range(len(predictions)):\n",
    "    if (predictions[i][0]>=predictions[i][1]):\n",
    "        if y_test[i] == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    else:\n",
    "        if y_test[i] == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "print(tp,fp,tn,fn)\n",
    "            \n",
    "acur = (tp + tn)/(tp+tn+fp+fn) * 100\n",
    "pre = tp / (tp+fp) * 100\n",
    "recall = tp / (tp+fn) * 100\n",
    "f1 = (2*pre*recall)/(pre+recall)\n",
    "print('Accuracy: ',acur,'\\n','Precission: ',pre,'\\n','Recall:',recall,'\\n','F1 Score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-12T00:47:48.363500Z",
     "iopub.status.busy": "2022-05-12T00:47:48.363269Z",
     "iopub.status.idle": "2022-05-12T00:47:48.373533Z",
     "shell.execute_reply": "2022-05-12T00:47:48.372692Z",
     "shell.execute_reply.started": "2022-05-12T00:47:48.363472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
