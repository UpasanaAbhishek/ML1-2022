{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a CNN model on the dataset which has been assigned to you. Print a classification report to see the model metrics on train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"dataset/train\"\n",
    "test = \"dataset/test\"\n",
    "train_labels = pd.read_csv('dataset/train.csv')\n",
    "test_labels = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('dataset/train.csv')\n",
    "labels_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images for resnet:\n",
      "Found 8227 validated image filenames belonging to 7 classes.\n",
      "Testing images for resnet:\n",
      "Found 2056 validated image filenames.\n",
      "Training images for efficientnet:\n",
      "Found 8227 validated image filenames belonging to 7 classes.\n",
      "Testing images for efficientnet:\n",
      "Found 2056 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#This is for resnet\n",
    "train_datagen_res = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen_res = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "#This is for efficientNet, which does not require image rescaling.\n",
    "train_datagen_eff = ImageDataGenerator(rescale=None)\n",
    "test_datagen_eff = ImageDataGenerator(rescale=None)\n",
    "\n",
    "\n",
    "print(\"Training images for resnet:\")\n",
    "train_data_res = train_datagen_res.flow_from_dataframe(dataframe=labels, \n",
    "                                                       directory=train,\n",
    "                                                       x_col='image_ID',\n",
    "                                                       y_col='label',\n",
    "                                                       target_size=IMAGE_SHAPE,\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       class_mode=\"categorical\")\n",
    "\n",
    "print(\"Testing images for resnet:\")\n",
    "test_data_res = test_datagen_res.flow_from_dataframe(dataframe=labels_test, \n",
    "                                                     directory=test,\n",
    "                                                     x_col='image_ID',\n",
    "                                                     target_size=IMAGE_SHAPE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     class_mode=None)\n",
    "\n",
    "print(\"Training images for efficientnet:\")\n",
    "train_data_eff = train_datagen_eff.flow_from_dataframe(dataframe=labels, \n",
    "                                                       directory=train,\n",
    "                                                       x_col='image_ID',\n",
    "                                                       y_col='label',\n",
    "                                                       target_size=IMAGE_SHAPE,\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       class_mode=\"categorical\")\n",
    "\n",
    "print(\"Testing images for efficientnet:\")\n",
    "test_data_eff = test_datagen_eff.flow_from_dataframe(dataframe=labels_test, \n",
    "                                                     directory=test,\n",
    "                                                     x_col='image_ID',\n",
    "                                                     target_size=IMAGE_SHAPE,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     class_mode=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet 50 V2 feature vector\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "\n",
    "# Original: EfficientNetB0 feature vector (version 1)\n",
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\umrah\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\umrah\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.23.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_model(model_url, num_classes=7): #Since there are 7 output classes in this dataset\n",
    "\n",
    "  # Download the pretrained model and save it as a Keras layer\n",
    "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                           trainable=False, # freeze the underlying patterns\n",
    "                                           name='feature_extraction_layer',\n",
    "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
    "  \n",
    "  # Create our own model\n",
    "  model = tf.keras.Sequential([\n",
    "    feature_extractor_layer, # use the feature extraction layer as the base\n",
    "    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "258/258 [==============================] - 713s 3s/step - loss: 0.6122 - accuracy: 0.7942 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "258/258 [==============================] - 547s 2s/step - loss: 0.2701 - accuracy: 0.9147 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "resnet_model = create_model(resnet_url, num_classes=7)\n",
    "\n",
    "# Compile\n",
    "resnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "resnet_history = resnet_model.fit(train_data_res,\n",
    "                                  epochs=2,\n",
    "                                  steps_per_epoch=len(train_data_res),\n",
    "                                  validation_data=test_data_res,\n",
    "                                  validation_steps=len(test_data_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extraction_layer (K  (None, 2048)             23564800  \n",
      " erasLayer)                                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 7)                 14343     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,579,143\n",
      "Trainable params: 14,343\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "258/258 [==============================] - 402s 2s/step - loss: 525.6364 - accuracy: 0.1843 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "258/258 [==============================] - 399s 2s/step - loss: 360.3878 - accuracy: 0.2134 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "efficientnet_model = create_model(model_url=efficientnet_url,\n",
    "                                  num_classes=7)\n",
    "\n",
    "# Compile EfficientNet model\n",
    "efficientnet_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(),\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Fit EfficientNet model \n",
    "efficientnet_history = efficientnet_model.fit(train_data_eff,\n",
    "                                              epochs=2,\n",
    "                                              steps_per_epoch=len(train_data_eff),\n",
    "                                              validation_data=test_data_eff,\n",
    "                                              validation_steps=len(test_data_eff))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " feature_extraction_layer (K  (None, 1280)             4049564   \n",
      " erasLayer)                                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 7)                 8967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,058,531\n",
      "Trainable params: 8,967\n",
      "Non-trainable params: 4,049,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "258/258 [==============================] - 3468s 13s/step - loss: 0.4869 - accuracy: 0.8280 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "258/258 [==============================] - 3076s 12s/step - loss: 0.2836 - accuracy: 0.9015 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "258/258 [==============================] - 2839s 11s/step - loss: 0.2342 - accuracy: 0.9210 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#Functional API\n",
    "# Create a functional model with data augmentation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Build data augmentation layer\n",
    "data_augmentation = Sequential([\n",
    "  preprocessing.RandomFlip('horizontal'),\n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomRotation(0.2),                 \n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Setup input shape and base model, unfreezing the base model layers\n",
    "input_shape = (224, 224, 3)\n",
    "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
    "base_model.trainable = True #Should be set to True for fine tuning\n",
    "\n",
    "# Freeze all layers except for the\n",
    "for layer in base_model.layers[:-10]:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Create input layer\n",
    "inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "# Add in data augmentation Sequential model as a layer\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Give base_model inputs (after augmentation) and don't train it\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Pool output features of base model\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "# Put a dense layer on as the output\n",
    "outputs = layers.Dense(7, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "# Make a model with inputs and outputs\n",
    "model_tuned = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_tuned.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_final_tuned = model_tuned.fit(train_data_eff,\n",
    "                    epochs=3,\n",
    "                    steps_per_epoch=len(train_data_eff),\n",
    "                    validation_data=test_data_eff,\n",
    "                    validation_steps=int(0.25* len(test_data_eff))) # validate for less steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 rescaling_1 False\n",
      "2 normalization_1 False\n",
      "3 tf.math.truediv_1 False\n",
      "4 stem_conv_pad False\n",
      "5 stem_conv False\n",
      "6 stem_bn False\n",
      "7 stem_activation False\n",
      "8 block1a_dwconv False\n",
      "9 block1a_bn False\n",
      "10 block1a_activation False\n",
      "11 block1a_se_squeeze False\n",
      "12 block1a_se_reshape False\n",
      "13 block1a_se_reduce False\n",
      "14 block1a_se_expand False\n",
      "15 block1a_se_excite False\n",
      "16 block1a_project_conv False\n",
      "17 block1a_project_bn False\n",
      "18 block1b_dwconv False\n",
      "19 block1b_bn False\n",
      "20 block1b_activation False\n",
      "21 block1b_se_squeeze False\n",
      "22 block1b_se_reshape False\n",
      "23 block1b_se_reduce False\n",
      "24 block1b_se_expand False\n",
      "25 block1b_se_excite False\n",
      "26 block1b_project_conv False\n",
      "27 block1b_project_bn False\n",
      "28 block1b_drop False\n",
      "29 block1b_add False\n",
      "30 block1c_dwconv False\n",
      "31 block1c_bn False\n",
      "32 block1c_activation False\n",
      "33 block1c_se_squeeze False\n",
      "34 block1c_se_reshape False\n",
      "35 block1c_se_reduce False\n",
      "36 block1c_se_expand False\n",
      "37 block1c_se_excite False\n",
      "38 block1c_project_conv False\n",
      "39 block1c_project_bn False\n",
      "40 block1c_drop False\n",
      "41 block1c_add False\n",
      "42 block1d_dwconv False\n",
      "43 block1d_bn False\n",
      "44 block1d_activation False\n",
      "45 block1d_se_squeeze False\n",
      "46 block1d_se_reshape False\n",
      "47 block1d_se_reduce False\n",
      "48 block1d_se_expand False\n",
      "49 block1d_se_excite False\n",
      "50 block1d_project_conv False\n",
      "51 block1d_project_bn False\n",
      "52 block1d_drop False\n",
      "53 block1d_add False\n",
      "54 block2a_expand_conv False\n",
      "55 block2a_expand_bn False\n",
      "56 block2a_expand_activation False\n",
      "57 block2a_dwconv_pad False\n",
      "58 block2a_dwconv False\n",
      "59 block2a_bn False\n",
      "60 block2a_activation False\n",
      "61 block2a_se_squeeze False\n",
      "62 block2a_se_reshape False\n",
      "63 block2a_se_reduce False\n",
      "64 block2a_se_expand False\n",
      "65 block2a_se_excite False\n",
      "66 block2a_project_conv False\n",
      "67 block2a_project_bn False\n",
      "68 block2b_expand_conv False\n",
      "69 block2b_expand_bn False\n",
      "70 block2b_expand_activation False\n",
      "71 block2b_dwconv False\n",
      "72 block2b_bn False\n",
      "73 block2b_activation False\n",
      "74 block2b_se_squeeze False\n",
      "75 block2b_se_reshape False\n",
      "76 block2b_se_reduce False\n",
      "77 block2b_se_expand False\n",
      "78 block2b_se_excite False\n",
      "79 block2b_project_conv False\n",
      "80 block2b_project_bn False\n",
      "81 block2b_drop False\n",
      "82 block2b_add False\n",
      "83 block2c_expand_conv False\n",
      "84 block2c_expand_bn False\n",
      "85 block2c_expand_activation False\n",
      "86 block2c_dwconv False\n",
      "87 block2c_bn False\n",
      "88 block2c_activation False\n",
      "89 block2c_se_squeeze False\n",
      "90 block2c_se_reshape False\n",
      "91 block2c_se_reduce False\n",
      "92 block2c_se_expand False\n",
      "93 block2c_se_excite False\n",
      "94 block2c_project_conv False\n",
      "95 block2c_project_bn False\n",
      "96 block2c_drop False\n",
      "97 block2c_add False\n",
      "98 block2d_expand_conv False\n",
      "99 block2d_expand_bn False\n",
      "100 block2d_expand_activation False\n",
      "101 block2d_dwconv False\n",
      "102 block2d_bn False\n",
      "103 block2d_activation False\n",
      "104 block2d_se_squeeze False\n",
      "105 block2d_se_reshape False\n",
      "106 block2d_se_reduce False\n",
      "107 block2d_se_expand False\n",
      "108 block2d_se_excite False\n",
      "109 block2d_project_conv False\n",
      "110 block2d_project_bn False\n",
      "111 block2d_drop False\n",
      "112 block2d_add False\n",
      "113 block2e_expand_conv False\n",
      "114 block2e_expand_bn False\n",
      "115 block2e_expand_activation False\n",
      "116 block2e_dwconv False\n",
      "117 block2e_bn False\n",
      "118 block2e_activation False\n",
      "119 block2e_se_squeeze False\n",
      "120 block2e_se_reshape False\n",
      "121 block2e_se_reduce False\n",
      "122 block2e_se_expand False\n",
      "123 block2e_se_excite False\n",
      "124 block2e_project_conv False\n",
      "125 block2e_project_bn False\n",
      "126 block2e_drop False\n",
      "127 block2e_add False\n",
      "128 block2f_expand_conv False\n",
      "129 block2f_expand_bn False\n",
      "130 block2f_expand_activation False\n",
      "131 block2f_dwconv False\n",
      "132 block2f_bn False\n",
      "133 block2f_activation False\n",
      "134 block2f_se_squeeze False\n",
      "135 block2f_se_reshape False\n",
      "136 block2f_se_reduce False\n",
      "137 block2f_se_expand False\n",
      "138 block2f_se_excite False\n",
      "139 block2f_project_conv False\n",
      "140 block2f_project_bn False\n",
      "141 block2f_drop False\n",
      "142 block2f_add False\n",
      "143 block2g_expand_conv False\n",
      "144 block2g_expand_bn False\n",
      "145 block2g_expand_activation False\n",
      "146 block2g_dwconv False\n",
      "147 block2g_bn False\n",
      "148 block2g_activation False\n",
      "149 block2g_se_squeeze False\n",
      "150 block2g_se_reshape False\n",
      "151 block2g_se_reduce False\n",
      "152 block2g_se_expand False\n",
      "153 block2g_se_excite False\n",
      "154 block2g_project_conv False\n",
      "155 block2g_project_bn False\n",
      "156 block2g_drop False\n",
      "157 block2g_add False\n",
      "158 block3a_expand_conv False\n",
      "159 block3a_expand_bn False\n",
      "160 block3a_expand_activation False\n",
      "161 block3a_dwconv_pad False\n",
      "162 block3a_dwconv False\n",
      "163 block3a_bn False\n",
      "164 block3a_activation False\n",
      "165 block3a_se_squeeze False\n",
      "166 block3a_se_reshape False\n",
      "167 block3a_se_reduce False\n",
      "168 block3a_se_expand False\n",
      "169 block3a_se_excite False\n",
      "170 block3a_project_conv False\n",
      "171 block3a_project_bn False\n",
      "172 block3b_expand_conv False\n",
      "173 block3b_expand_bn False\n",
      "174 block3b_expand_activation False\n",
      "175 block3b_dwconv False\n",
      "176 block3b_bn False\n",
      "177 block3b_activation False\n",
      "178 block3b_se_squeeze False\n",
      "179 block3b_se_reshape False\n",
      "180 block3b_se_reduce False\n",
      "181 block3b_se_expand False\n",
      "182 block3b_se_excite False\n",
      "183 block3b_project_conv False\n",
      "184 block3b_project_bn False\n",
      "185 block3b_drop False\n",
      "186 block3b_add False\n",
      "187 block3c_expand_conv False\n",
      "188 block3c_expand_bn False\n",
      "189 block3c_expand_activation False\n",
      "190 block3c_dwconv False\n",
      "191 block3c_bn False\n",
      "192 block3c_activation False\n",
      "193 block3c_se_squeeze False\n",
      "194 block3c_se_reshape False\n",
      "195 block3c_se_reduce False\n",
      "196 block3c_se_expand False\n",
      "197 block3c_se_excite False\n",
      "198 block3c_project_conv False\n",
      "199 block3c_project_bn False\n",
      "200 block3c_drop False\n",
      "201 block3c_add False\n",
      "202 block3d_expand_conv False\n",
      "203 block3d_expand_bn False\n",
      "204 block3d_expand_activation False\n",
      "205 block3d_dwconv False\n",
      "206 block3d_bn False\n",
      "207 block3d_activation False\n",
      "208 block3d_se_squeeze False\n",
      "209 block3d_se_reshape False\n",
      "210 block3d_se_reduce False\n",
      "211 block3d_se_expand False\n",
      "212 block3d_se_excite False\n",
      "213 block3d_project_conv False\n",
      "214 block3d_project_bn False\n",
      "215 block3d_drop False\n",
      "216 block3d_add False\n",
      "217 block3e_expand_conv False\n",
      "218 block3e_expand_bn False\n",
      "219 block3e_expand_activation False\n",
      "220 block3e_dwconv False\n",
      "221 block3e_bn False\n",
      "222 block3e_activation False\n",
      "223 block3e_se_squeeze False\n",
      "224 block3e_se_reshape False\n",
      "225 block3e_se_reduce False\n",
      "226 block3e_se_expand False\n",
      "227 block3e_se_excite False\n",
      "228 block3e_project_conv False\n",
      "229 block3e_project_bn False\n",
      "230 block3e_drop False\n",
      "231 block3e_add False\n",
      "232 block3f_expand_conv False\n",
      "233 block3f_expand_bn False\n",
      "234 block3f_expand_activation False\n",
      "235 block3f_dwconv False\n",
      "236 block3f_bn False\n",
      "237 block3f_activation False\n",
      "238 block3f_se_squeeze False\n",
      "239 block3f_se_reshape False\n",
      "240 block3f_se_reduce False\n",
      "241 block3f_se_expand False\n",
      "242 block3f_se_excite False\n",
      "243 block3f_project_conv False\n",
      "244 block3f_project_bn False\n",
      "245 block3f_drop False\n",
      "246 block3f_add False\n",
      "247 block3g_expand_conv False\n",
      "248 block3g_expand_bn False\n",
      "249 block3g_expand_activation False\n",
      "250 block3g_dwconv False\n",
      "251 block3g_bn False\n",
      "252 block3g_activation False\n",
      "253 block3g_se_squeeze False\n",
      "254 block3g_se_reshape False\n",
      "255 block3g_se_reduce False\n",
      "256 block3g_se_expand False\n",
      "257 block3g_se_excite False\n",
      "258 block3g_project_conv False\n",
      "259 block3g_project_bn False\n",
      "260 block3g_drop False\n",
      "261 block3g_add False\n",
      "262 block4a_expand_conv False\n",
      "263 block4a_expand_bn False\n",
      "264 block4a_expand_activation False\n",
      "265 block4a_dwconv_pad False\n",
      "266 block4a_dwconv False\n",
      "267 block4a_bn False\n",
      "268 block4a_activation False\n",
      "269 block4a_se_squeeze False\n",
      "270 block4a_se_reshape False\n",
      "271 block4a_se_reduce False\n",
      "272 block4a_se_expand False\n",
      "273 block4a_se_excite False\n",
      "274 block4a_project_conv False\n",
      "275 block4a_project_bn False\n",
      "276 block4b_expand_conv False\n",
      "277 block4b_expand_bn False\n",
      "278 block4b_expand_activation False\n",
      "279 block4b_dwconv False\n",
      "280 block4b_bn False\n",
      "281 block4b_activation False\n",
      "282 block4b_se_squeeze False\n",
      "283 block4b_se_reshape False\n",
      "284 block4b_se_reduce False\n",
      "285 block4b_se_expand False\n",
      "286 block4b_se_excite False\n",
      "287 block4b_project_conv False\n",
      "288 block4b_project_bn False\n",
      "289 block4b_drop False\n",
      "290 block4b_add False\n",
      "291 block4c_expand_conv False\n",
      "292 block4c_expand_bn False\n",
      "293 block4c_expand_activation False\n",
      "294 block4c_dwconv False\n",
      "295 block4c_bn False\n",
      "296 block4c_activation False\n",
      "297 block4c_se_squeeze False\n",
      "298 block4c_se_reshape False\n",
      "299 block4c_se_reduce False\n",
      "300 block4c_se_expand False\n",
      "301 block4c_se_excite False\n",
      "302 block4c_project_conv False\n",
      "303 block4c_project_bn False\n",
      "304 block4c_drop False\n",
      "305 block4c_add False\n",
      "306 block4d_expand_conv False\n",
      "307 block4d_expand_bn False\n",
      "308 block4d_expand_activation False\n",
      "309 block4d_dwconv False\n",
      "310 block4d_bn False\n",
      "311 block4d_activation False\n",
      "312 block4d_se_squeeze False\n",
      "313 block4d_se_reshape False\n",
      "314 block4d_se_reduce False\n",
      "315 block4d_se_expand False\n",
      "316 block4d_se_excite False\n",
      "317 block4d_project_conv False\n",
      "318 block4d_project_bn False\n",
      "319 block4d_drop False\n",
      "320 block4d_add False\n",
      "321 block4e_expand_conv False\n",
      "322 block4e_expand_bn False\n",
      "323 block4e_expand_activation False\n",
      "324 block4e_dwconv False\n",
      "325 block4e_bn False\n",
      "326 block4e_activation False\n",
      "327 block4e_se_squeeze False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 block4e_se_reshape False\n",
      "329 block4e_se_reduce False\n",
      "330 block4e_se_expand False\n",
      "331 block4e_se_excite False\n",
      "332 block4e_project_conv False\n",
      "333 block4e_project_bn False\n",
      "334 block4e_drop False\n",
      "335 block4e_add False\n",
      "336 block4f_expand_conv False\n",
      "337 block4f_expand_bn False\n",
      "338 block4f_expand_activation False\n",
      "339 block4f_dwconv False\n",
      "340 block4f_bn False\n",
      "341 block4f_activation False\n",
      "342 block4f_se_squeeze False\n",
      "343 block4f_se_reshape False\n",
      "344 block4f_se_reduce False\n",
      "345 block4f_se_expand False\n",
      "346 block4f_se_excite False\n",
      "347 block4f_project_conv False\n",
      "348 block4f_project_bn False\n",
      "349 block4f_drop False\n",
      "350 block4f_add False\n",
      "351 block4g_expand_conv False\n",
      "352 block4g_expand_bn False\n",
      "353 block4g_expand_activation False\n",
      "354 block4g_dwconv False\n",
      "355 block4g_bn False\n",
      "356 block4g_activation False\n",
      "357 block4g_se_squeeze False\n",
      "358 block4g_se_reshape False\n",
      "359 block4g_se_reduce False\n",
      "360 block4g_se_expand False\n",
      "361 block4g_se_excite False\n",
      "362 block4g_project_conv False\n",
      "363 block4g_project_bn False\n",
      "364 block4g_drop False\n",
      "365 block4g_add False\n",
      "366 block4h_expand_conv False\n",
      "367 block4h_expand_bn False\n",
      "368 block4h_expand_activation False\n",
      "369 block4h_dwconv False\n",
      "370 block4h_bn False\n",
      "371 block4h_activation False\n",
      "372 block4h_se_squeeze False\n",
      "373 block4h_se_reshape False\n",
      "374 block4h_se_reduce False\n",
      "375 block4h_se_expand False\n",
      "376 block4h_se_excite False\n",
      "377 block4h_project_conv False\n",
      "378 block4h_project_bn False\n",
      "379 block4h_drop False\n",
      "380 block4h_add False\n",
      "381 block4i_expand_conv False\n",
      "382 block4i_expand_bn False\n",
      "383 block4i_expand_activation False\n",
      "384 block4i_dwconv False\n",
      "385 block4i_bn False\n",
      "386 block4i_activation False\n",
      "387 block4i_se_squeeze False\n",
      "388 block4i_se_reshape False\n",
      "389 block4i_se_reduce False\n",
      "390 block4i_se_expand False\n",
      "391 block4i_se_excite False\n",
      "392 block4i_project_conv False\n",
      "393 block4i_project_bn False\n",
      "394 block4i_drop False\n",
      "395 block4i_add False\n",
      "396 block4j_expand_conv False\n",
      "397 block4j_expand_bn False\n",
      "398 block4j_expand_activation False\n",
      "399 block4j_dwconv False\n",
      "400 block4j_bn False\n",
      "401 block4j_activation False\n",
      "402 block4j_se_squeeze False\n",
      "403 block4j_se_reshape False\n",
      "404 block4j_se_reduce False\n",
      "405 block4j_se_expand False\n",
      "406 block4j_se_excite False\n",
      "407 block4j_project_conv False\n",
      "408 block4j_project_bn False\n",
      "409 block4j_drop False\n",
      "410 block4j_add False\n",
      "411 block5a_expand_conv False\n",
      "412 block5a_expand_bn False\n",
      "413 block5a_expand_activation False\n",
      "414 block5a_dwconv False\n",
      "415 block5a_bn False\n",
      "416 block5a_activation False\n",
      "417 block5a_se_squeeze False\n",
      "418 block5a_se_reshape False\n",
      "419 block5a_se_reduce False\n",
      "420 block5a_se_expand False\n",
      "421 block5a_se_excite False\n",
      "422 block5a_project_conv False\n",
      "423 block5a_project_bn False\n",
      "424 block5b_expand_conv False\n",
      "425 block5b_expand_bn False\n",
      "426 block5b_expand_activation False\n",
      "427 block5b_dwconv False\n",
      "428 block5b_bn False\n",
      "429 block5b_activation False\n",
      "430 block5b_se_squeeze False\n",
      "431 block5b_se_reshape False\n",
      "432 block5b_se_reduce False\n",
      "433 block5b_se_expand False\n",
      "434 block5b_se_excite False\n",
      "435 block5b_project_conv False\n",
      "436 block5b_project_bn False\n",
      "437 block5b_drop False\n",
      "438 block5b_add False\n",
      "439 block5c_expand_conv False\n",
      "440 block5c_expand_bn False\n",
      "441 block5c_expand_activation False\n",
      "442 block5c_dwconv False\n",
      "443 block5c_bn False\n",
      "444 block5c_activation False\n",
      "445 block5c_se_squeeze False\n",
      "446 block5c_se_reshape False\n",
      "447 block5c_se_reduce False\n",
      "448 block5c_se_expand False\n",
      "449 block5c_se_excite False\n",
      "450 block5c_project_conv False\n",
      "451 block5c_project_bn False\n",
      "452 block5c_drop False\n",
      "453 block5c_add False\n",
      "454 block5d_expand_conv False\n",
      "455 block5d_expand_bn False\n",
      "456 block5d_expand_activation False\n",
      "457 block5d_dwconv False\n",
      "458 block5d_bn False\n",
      "459 block5d_activation False\n",
      "460 block5d_se_squeeze False\n",
      "461 block5d_se_reshape False\n",
      "462 block5d_se_reduce False\n",
      "463 block5d_se_expand False\n",
      "464 block5d_se_excite False\n",
      "465 block5d_project_conv False\n",
      "466 block5d_project_bn False\n",
      "467 block5d_drop False\n",
      "468 block5d_add False\n",
      "469 block5e_expand_conv False\n",
      "470 block5e_expand_bn False\n",
      "471 block5e_expand_activation False\n",
      "472 block5e_dwconv False\n",
      "473 block5e_bn False\n",
      "474 block5e_activation False\n",
      "475 block5e_se_squeeze False\n",
      "476 block5e_se_reshape False\n",
      "477 block5e_se_reduce False\n",
      "478 block5e_se_expand False\n",
      "479 block5e_se_excite False\n",
      "480 block5e_project_conv False\n",
      "481 block5e_project_bn False\n",
      "482 block5e_drop False\n",
      "483 block5e_add False\n",
      "484 block5f_expand_conv False\n",
      "485 block5f_expand_bn False\n",
      "486 block5f_expand_activation False\n",
      "487 block5f_dwconv False\n",
      "488 block5f_bn False\n",
      "489 block5f_activation False\n",
      "490 block5f_se_squeeze False\n",
      "491 block5f_se_reshape False\n",
      "492 block5f_se_reduce False\n",
      "493 block5f_se_expand False\n",
      "494 block5f_se_excite False\n",
      "495 block5f_project_conv False\n",
      "496 block5f_project_bn False\n",
      "497 block5f_drop False\n",
      "498 block5f_add False\n",
      "499 block5g_expand_conv False\n",
      "500 block5g_expand_bn False\n",
      "501 block5g_expand_activation False\n",
      "502 block5g_dwconv False\n",
      "503 block5g_bn False\n",
      "504 block5g_activation False\n",
      "505 block5g_se_squeeze False\n",
      "506 block5g_se_reshape False\n",
      "507 block5g_se_reduce False\n",
      "508 block5g_se_expand False\n",
      "509 block5g_se_excite False\n",
      "510 block5g_project_conv False\n",
      "511 block5g_project_bn False\n",
      "512 block5g_drop False\n",
      "513 block5g_add False\n",
      "514 block5h_expand_conv False\n",
      "515 block5h_expand_bn False\n",
      "516 block5h_expand_activation False\n",
      "517 block5h_dwconv False\n",
      "518 block5h_bn False\n",
      "519 block5h_activation False\n",
      "520 block5h_se_squeeze False\n",
      "521 block5h_se_reshape False\n",
      "522 block5h_se_reduce False\n",
      "523 block5h_se_expand False\n",
      "524 block5h_se_excite False\n",
      "525 block5h_project_conv False\n",
      "526 block5h_project_bn False\n",
      "527 block5h_drop False\n",
      "528 block5h_add False\n",
      "529 block5i_expand_conv False\n",
      "530 block5i_expand_bn False\n",
      "531 block5i_expand_activation False\n",
      "532 block5i_dwconv False\n",
      "533 block5i_bn False\n",
      "534 block5i_activation False\n",
      "535 block5i_se_squeeze False\n",
      "536 block5i_se_reshape False\n",
      "537 block5i_se_reduce False\n",
      "538 block5i_se_expand False\n",
      "539 block5i_se_excite False\n",
      "540 block5i_project_conv False\n",
      "541 block5i_project_bn False\n",
      "542 block5i_drop False\n",
      "543 block5i_add False\n",
      "544 block5j_expand_conv False\n",
      "545 block5j_expand_bn False\n",
      "546 block5j_expand_activation False\n",
      "547 block5j_dwconv False\n",
      "548 block5j_bn False\n",
      "549 block5j_activation False\n",
      "550 block5j_se_squeeze False\n",
      "551 block5j_se_reshape False\n",
      "552 block5j_se_reduce False\n",
      "553 block5j_se_expand False\n",
      "554 block5j_se_excite False\n",
      "555 block5j_project_conv False\n",
      "556 block5j_project_bn False\n",
      "557 block5j_drop False\n",
      "558 block5j_add False\n",
      "559 block6a_expand_conv False\n",
      "560 block6a_expand_bn False\n",
      "561 block6a_expand_activation False\n",
      "562 block6a_dwconv_pad False\n",
      "563 block6a_dwconv False\n",
      "564 block6a_bn False\n",
      "565 block6a_activation False\n",
      "566 block6a_se_squeeze False\n",
      "567 block6a_se_reshape False\n",
      "568 block6a_se_reduce False\n",
      "569 block6a_se_expand False\n",
      "570 block6a_se_excite False\n",
      "571 block6a_project_conv False\n",
      "572 block6a_project_bn False\n",
      "573 block6b_expand_conv False\n",
      "574 block6b_expand_bn False\n",
      "575 block6b_expand_activation False\n",
      "576 block6b_dwconv False\n",
      "577 block6b_bn False\n",
      "578 block6b_activation False\n",
      "579 block6b_se_squeeze False\n",
      "580 block6b_se_reshape False\n",
      "581 block6b_se_reduce False\n",
      "582 block6b_se_expand False\n",
      "583 block6b_se_excite False\n",
      "584 block6b_project_conv False\n",
      "585 block6b_project_bn False\n",
      "586 block6b_drop False\n",
      "587 block6b_add False\n",
      "588 block6c_expand_conv False\n",
      "589 block6c_expand_bn False\n",
      "590 block6c_expand_activation False\n",
      "591 block6c_dwconv False\n",
      "592 block6c_bn False\n",
      "593 block6c_activation False\n",
      "594 block6c_se_squeeze False\n",
      "595 block6c_se_reshape False\n",
      "596 block6c_se_reduce False\n",
      "597 block6c_se_expand False\n",
      "598 block6c_se_excite False\n",
      "599 block6c_project_conv False\n",
      "600 block6c_project_bn False\n",
      "601 block6c_drop False\n",
      "602 block6c_add False\n",
      "603 block6d_expand_conv False\n",
      "604 block6d_expand_bn False\n",
      "605 block6d_expand_activation False\n",
      "606 block6d_dwconv False\n",
      "607 block6d_bn False\n",
      "608 block6d_activation False\n",
      "609 block6d_se_squeeze False\n",
      "610 block6d_se_reshape False\n",
      "611 block6d_se_reduce False\n",
      "612 block6d_se_expand False\n",
      "613 block6d_se_excite False\n",
      "614 block6d_project_conv False\n",
      "615 block6d_project_bn False\n",
      "616 block6d_drop False\n",
      "617 block6d_add False\n",
      "618 block6e_expand_conv False\n",
      "619 block6e_expand_bn False\n",
      "620 block6e_expand_activation False\n",
      "621 block6e_dwconv False\n",
      "622 block6e_bn False\n",
      "623 block6e_activation False\n",
      "624 block6e_se_squeeze False\n",
      "625 block6e_se_reshape False\n",
      "626 block6e_se_reduce False\n",
      "627 block6e_se_expand False\n",
      "628 block6e_se_excite False\n",
      "629 block6e_project_conv False\n",
      "630 block6e_project_bn False\n",
      "631 block6e_drop False\n",
      "632 block6e_add False\n",
      "633 block6f_expand_conv False\n",
      "634 block6f_expand_bn False\n",
      "635 block6f_expand_activation False\n",
      "636 block6f_dwconv False\n",
      "637 block6f_bn False\n",
      "638 block6f_activation False\n",
      "639 block6f_se_squeeze False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 block6f_se_reshape False\n",
      "641 block6f_se_reduce False\n",
      "642 block6f_se_expand False\n",
      "643 block6f_se_excite False\n",
      "644 block6f_project_conv False\n",
      "645 block6f_project_bn False\n",
      "646 block6f_drop False\n",
      "647 block6f_add False\n",
      "648 block6g_expand_conv False\n",
      "649 block6g_expand_bn False\n",
      "650 block6g_expand_activation False\n",
      "651 block6g_dwconv False\n",
      "652 block6g_bn False\n",
      "653 block6g_activation False\n",
      "654 block6g_se_squeeze False\n",
      "655 block6g_se_reshape False\n",
      "656 block6g_se_reduce False\n",
      "657 block6g_se_expand False\n",
      "658 block6g_se_excite False\n",
      "659 block6g_project_conv False\n",
      "660 block6g_project_bn False\n",
      "661 block6g_drop False\n",
      "662 block6g_add False\n",
      "663 block6h_expand_conv False\n",
      "664 block6h_expand_bn False\n",
      "665 block6h_expand_activation False\n",
      "666 block6h_dwconv False\n",
      "667 block6h_bn False\n",
      "668 block6h_activation False\n",
      "669 block6h_se_squeeze False\n",
      "670 block6h_se_reshape False\n",
      "671 block6h_se_reduce False\n",
      "672 block6h_se_expand False\n",
      "673 block6h_se_excite False\n",
      "674 block6h_project_conv False\n",
      "675 block6h_project_bn False\n",
      "676 block6h_drop False\n",
      "677 block6h_add False\n",
      "678 block6i_expand_conv False\n",
      "679 block6i_expand_bn False\n",
      "680 block6i_expand_activation False\n",
      "681 block6i_dwconv False\n",
      "682 block6i_bn False\n",
      "683 block6i_activation False\n",
      "684 block6i_se_squeeze False\n",
      "685 block6i_se_reshape False\n",
      "686 block6i_se_reduce False\n",
      "687 block6i_se_expand False\n",
      "688 block6i_se_excite False\n",
      "689 block6i_project_conv False\n",
      "690 block6i_project_bn False\n",
      "691 block6i_drop False\n",
      "692 block6i_add False\n",
      "693 block6j_expand_conv False\n",
      "694 block6j_expand_bn False\n",
      "695 block6j_expand_activation False\n",
      "696 block6j_dwconv False\n",
      "697 block6j_bn False\n",
      "698 block6j_activation False\n",
      "699 block6j_se_squeeze False\n",
      "700 block6j_se_reshape False\n",
      "701 block6j_se_reduce False\n",
      "702 block6j_se_expand False\n",
      "703 block6j_se_excite False\n",
      "704 block6j_project_conv False\n",
      "705 block6j_project_bn False\n",
      "706 block6j_drop False\n",
      "707 block6j_add False\n",
      "708 block6k_expand_conv False\n",
      "709 block6k_expand_bn False\n",
      "710 block6k_expand_activation False\n",
      "711 block6k_dwconv False\n",
      "712 block6k_bn False\n",
      "713 block6k_activation False\n",
      "714 block6k_se_squeeze False\n",
      "715 block6k_se_reshape False\n",
      "716 block6k_se_reduce False\n",
      "717 block6k_se_expand False\n",
      "718 block6k_se_excite False\n",
      "719 block6k_project_conv False\n",
      "720 block6k_project_bn False\n",
      "721 block6k_drop False\n",
      "722 block6k_add False\n",
      "723 block6l_expand_conv False\n",
      "724 block6l_expand_bn False\n",
      "725 block6l_expand_activation False\n",
      "726 block6l_dwconv False\n",
      "727 block6l_bn False\n",
      "728 block6l_activation False\n",
      "729 block6l_se_squeeze False\n",
      "730 block6l_se_reshape False\n",
      "731 block6l_se_reduce False\n",
      "732 block6l_se_expand False\n",
      "733 block6l_se_excite False\n",
      "734 block6l_project_conv False\n",
      "735 block6l_project_bn False\n",
      "736 block6l_drop False\n",
      "737 block6l_add False\n",
      "738 block6m_expand_conv False\n",
      "739 block6m_expand_bn False\n",
      "740 block6m_expand_activation False\n",
      "741 block6m_dwconv False\n",
      "742 block6m_bn False\n",
      "743 block6m_activation False\n",
      "744 block6m_se_squeeze False\n",
      "745 block6m_se_reshape False\n",
      "746 block6m_se_reduce False\n",
      "747 block6m_se_expand False\n",
      "748 block6m_se_excite False\n",
      "749 block6m_project_conv False\n",
      "750 block6m_project_bn False\n",
      "751 block6m_drop False\n",
      "752 block6m_add False\n",
      "753 block7a_expand_conv False\n",
      "754 block7a_expand_bn False\n",
      "755 block7a_expand_activation False\n",
      "756 block7a_dwconv False\n",
      "757 block7a_bn False\n",
      "758 block7a_activation False\n",
      "759 block7a_se_squeeze False\n",
      "760 block7a_se_reshape False\n",
      "761 block7a_se_reduce False\n",
      "762 block7a_se_expand False\n",
      "763 block7a_se_excite False\n",
      "764 block7a_project_conv False\n",
      "765 block7a_project_bn False\n",
      "766 block7b_expand_conv False\n",
      "767 block7b_expand_bn False\n",
      "768 block7b_expand_activation False\n",
      "769 block7b_dwconv False\n",
      "770 block7b_bn False\n",
      "771 block7b_activation False\n",
      "772 block7b_se_squeeze False\n",
      "773 block7b_se_reshape False\n",
      "774 block7b_se_reduce False\n",
      "775 block7b_se_expand False\n",
      "776 block7b_se_excite False\n",
      "777 block7b_project_conv False\n",
      "778 block7b_project_bn False\n",
      "779 block7b_drop False\n",
      "780 block7b_add False\n",
      "781 block7c_expand_conv False\n",
      "782 block7c_expand_bn False\n",
      "783 block7c_expand_activation False\n",
      "784 block7c_dwconv False\n",
      "785 block7c_bn False\n",
      "786 block7c_activation False\n",
      "787 block7c_se_squeeze False\n",
      "788 block7c_se_reshape False\n",
      "789 block7c_se_reduce False\n",
      "790 block7c_se_expand False\n",
      "791 block7c_se_excite False\n",
      "792 block7c_project_conv False\n",
      "793 block7c_project_bn False\n",
      "794 block7c_drop False\n",
      "795 block7c_add False\n",
      "796 block7d_expand_conv False\n",
      "797 block7d_expand_bn False\n",
      "798 block7d_expand_activation False\n",
      "799 block7d_dwconv False\n",
      "800 block7d_bn False\n",
      "801 block7d_activation False\n",
      "802 block7d_se_squeeze False\n",
      "803 block7d_se_reshape False\n",
      "804 block7d_se_reduce True\n",
      "805 block7d_se_expand True\n",
      "806 block7d_se_excite True\n",
      "807 block7d_project_conv True\n",
      "808 block7d_project_bn True\n",
      "809 block7d_drop True\n",
      "810 block7d_add True\n",
      "811 top_conv True\n",
      "812 top_bn True\n",
      "813 top_activation True\n"
     ]
    }
   ],
   "source": [
    "# Check which layers got tuned in the base model-EfficientNet (trainable)\n",
    "for layer_number, layer in enumerate(base_model.layers):\n",
    "  print(layer_number, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " efficientnetb7 (Functional)  (None, None, None, 2560)  64097687 \n",
      "                                                                 \n",
      " global_average_pooling_laye  (None, 2560)             0         \n",
      " r (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 7)                 17927     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,115,614\n",
      "Trainable params: 5,353,127\n",
      "Non-trainable params: 58,762,487\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tuned.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Stride, Padding & Pooling? Explain with an example.\n",
    "Strides\n",
    "When the array is created, the pixels are shifted over to the input matrix. The number of pixels turning to the input matrix is known as the strides. When the number of strides is 1, we move the filters to 1 pixel at a time. Similarly, when the number of strides is 2, we carry the filters to 2 pixels, and so on. They are essential because they control the convolution of the filter against the input, i.e., Strides are responsible for regulating the features that could be missed while flattening the image. They denote the number of steps we are moving in each convolution. \n",
    "\n",
    "Padding\n",
    "The padding plays a vital role in creating CNN. After the convolution operation, the original size of the image is shrunk. Also, in the image classification task, there are multiple convolution layers after which our original image is shrunk after every step, which we dont want. \n",
    "\n",
    "Secondly, when the kernel moves over the original image, it passes through the middle layer more times than the edge layers, due to which there occurs an overlap.\n",
    "\n",
    "To overcome this problem, a new concept was introduced named padding. It is an additional layer that can add to the borders of an image while preserving the size of the original picture. \n",
    "\n",
    "Pooling\n",
    "The pooling layer is another building block of a CNN and plays a vital role in pre-processing an image. In the pre-process, the image size shrinks by reducing the number of parameters if the image is too large. When the picture is shrunk, the pixel density is also reduced, the downscaled image is obtained from the previous layers. Basically, its function is to progressively reduce the spatial size of the image to reduce the network complexity and computational cost. Spatial pooling is also known as downsampling or subsampling that reduces the dimensionality of each map but retains the essential features. A rectified linear activation function, or ReLU, is applied to each value in the feature map. Relu is a simple and effective nonlinearity that does not change the values in the feature map but is present because later subsequent pooling layers are added.\n",
    "References : https://www.codingninjas.com/codestudio/library/convolution-layer-padding-stride-and-pooling-in-cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is overfitting? How to overcome overfitting in an ML model?\n",
    "Overfitting occurs when you achieve a good fit of your model on the training data, while it does not generalize well on new, unseen data. In other words, the model learned patterns specific to the training data, which are irrelevant in other data.\n",
    "\n",
    "We can identify overfitting by looking at validation metrics, like loss or accuracy. Usually, the validation metric stops improving after a certain number of epochs and begins to decrease afterward. The training metric continues to improve because the model seeks to find the best fit for the training data.\n",
    "\n",
    "There are several manners in which we can reduce overfitting in deep learning models. The best option is to get more training data. Unfortunately, in real-world situations, we often do not have this possibility due to time, budget or technical constraints.\n",
    "\n",
    "Another way to reduce overfitting is to lower the capacity of the model to memorize the training data. As such, the model will need to focus on the relevant patterns in the training data, which results in better generalization. \n",
    "Controlling the iteration is also known as the early stopping method in machine learning, this overfitting avoidance technique works only when we have a process where our machine learning model learns iteratively.\n",
    "If our models learning process is iterative, then there is a specific point or iteration until which the model learns new features that we need our model to learn, however, after a certain point, our model will learn noises and that will lead to the condition of overfitting of the model.\n",
    "Cross-validation is another technique in machine learning that provides the method to solve the overfitting condition. Just like ensemble learning, cross-validation also divides the dataset, but the working is different.\n",
    "\n",
    "In cross-validation, training data is made to split into several other small train-test splits. These splits help in reducing the error in the model. Now in order to predict the likeability of an event happening, we could use various machine learning algorithms like K-nearest neighbor, support vector machines, or logistic regression, cross-validation provides a method with which we can find the right machine learning algorithm, this is also the reason how it prevents overfitting.\n",
    "We split usually 75% of the data for training, and the rest 25% for testing, or maybe the split is of 80-20, now the real question is which part of the dataset to keep for training and which for testing, to avoid this confusion, cross-validation cleverly uses 100% data for testing. \n",
    "For example, cross-validation would take first 75% of the data for the testing and rest 25% for training and store the results, then it will take first 25% of the data as testing and rest 75% of data for training, this is how every 25% block from the dataset is tested and the result is compared. \n",
    "Regularization is another powerful and arguably the most used machine learning technique to avoid overfitting, this method fits the function of the training dataset. This process makes the coefficient shift towards zero, hence reducing the errors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
